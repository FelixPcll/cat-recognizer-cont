{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, InputLayer\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 150\n",
    "LEARNING_RATE = 1e-3\n",
    "TRAIN_PATH = 'C:\\\\Users\\\\felix\\\\OneDrive\\\\Documentos\\\\Git\\\\cat-rec\\\\data\\\\vectorized data\\\\train_data.npy'\n",
    "TEST_PATH = 'C:\\\\Users\\\\felix\\\\OneDrive\\\\Documentos\\\\Git\\\\cat-rec\\\\data\\\\vectorized data\\\\test_data.npy'\n",
    "IMAGE_TEST = 'C:\\\\Users\\\\felix\\\\OneDrive\\\\Documentos\\\\Git\\\\cat-rec\\\\nn\\\\test img\\\\img.JPG'\n",
    "ONE_HOT = np.array(['American Shorthair', 'Angora', 'Ashera', 'British Shorthair',\n",
    "                    'Exotic', 'Himalayan', 'Maine Coon', 'Persian', 'Ragdoll', 'Siamese', 'Sphynx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG19(include_top=False,\n",
    "               weights='imagenet',\n",
    "               input_shape=(150, 150, 3),\n",
    "               classes=11)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "for layer in vgg.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1024, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = np.load(TRAIN_PATH), np.load(TEST_PATH)\n",
    "\n",
    "train_features = train_data[:, 0]\n",
    "train_features = np.array([list(i) for i in train_features]).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "train_labels = train_data[:, 1]\n",
    "train_labels = np.array([list(i) for i in train_labels])\n",
    "\n",
    "\n",
    "test_features = test_data[:, 0]\n",
    "test_features = np.array([list(i) for i in test_features]).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "test_labels = test_data[:, 1]\n",
    "test_labels = np.array([list(i) for i in test_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = TensorBoard()\n",
    "tb.set_model('VGG19(drop)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(x=train_features,\n",
    "          y=train_labels,\n",
    "          batch_size=50,\n",
    "          epochs=140,\n",
    "          validation_data=(test_features, test_labels),\n",
    "          verbose=1,\n",
    "          callbacks=[tb],\n",
    "          initial_epoch=70\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('.\\\\models\\\\VGG19(drop)\\\\VGG19(drop)-140_epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_square(image_current_path, shape):\n",
    "    \"\"\"Resize the image to a square shape keeping it's original proportion\n",
    "    and filling the rest of image with black pads to keep it square.\n",
    "\n",
    "    :param image_current_path: the local path where the image is.\n",
    "    :type image_current_path: OS string\n",
    "    :param shape: number of pixels per axis of the converted image\n",
    "    :type shape: int\n",
    "    :param save_path: path where the converted image must be saved\n",
    "    :type save_path: OS string\n",
    "    \"\"\"\n",
    "\n",
    "    original_image = cv2.imread(image_current_path, 1)\n",
    "    original_size = original_image.shape[:2]  # (height, width)\n",
    "\n",
    "    ratio = float(shape)/max(original_size)\n",
    "\n",
    "    format_size = tuple(reversed([int(i*ratio)\n",
    "                                  for i in original_size]))  # (width, height)\n",
    "\n",
    "    resized_image = cv2.resize(original_image, format_size)\n",
    "\n",
    "    d_w = shape - format_size[0]\n",
    "    d_h = shape - format_size[1]\n",
    "\n",
    "    top, bottom = d_h//2, d_h-(d_h//2)\n",
    "    left, right = d_w//2, d_w-(d_w//2)\n",
    "\n",
    "    color = [0, 0, 0]\n",
    "\n",
    "    squared_image = cv2.copyMakeBorder(\n",
    "        resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    return squared_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = resize_square(IMAGE_TEST, IMAGE_SIZE)\n",
    "img = np.array(img)/255\n",
    "\n",
    "out = model.predict([img.reshape(-1, 150, 150, 3)])[0]\n",
    "\n",
    "for n in range(11):\n",
    "    print('{} - {:2.2f}%'.format(ONE_HOT[n], out[n]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
