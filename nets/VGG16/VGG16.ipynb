{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, InputLayer\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 150\n",
    "LEARNING_RATE = 1e-3\n",
    "TRAIN_PATH = 'C:\\\\Users\\\\felix\\\\OneDrive\\\\Documentos\\\\Git\\\\cat-rec\\\\data\\\\vectorized data\\\\train_data.npy'\n",
    "TEST_PATH = 'C:\\\\Users\\\\felix\\\\OneDrive\\\\Documentos\\\\Git\\\\cat-rec\\\\data\\\\vectorized data\\\\test_data.npy'\n",
    "IMAGE_TEST = 'C:\\\\Users\\\\felix\\\\OneDrive\\\\Documentos\\\\Git\\\\cat-rec\\\\nn\\\\test img\\\\img.JPG'\n",
    "ONE_HOT = np.array(['American Shorthair', 'Angora', 'Ashera', 'British Shorthair',\n",
    "                    'Exotic', 'Himalayan', 'Maine Coon', 'Persian', 'Ragdoll', 'Siamese', 'Sphynx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                11275     \n",
      "=================================================================\n",
      "Total params: 24,165,195\n",
      "Trainable params: 9,450,507\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "for layer in vgg.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, activation='tanh'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='tanh'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = np.load(TRAIN_PATH), np.load(TEST_PATH)\n",
    "\n",
    "train_features = train_data[:, 0]\n",
    "train_features = np.array([list(i) for i in train_features]).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "train_labels = train_data[:, 1]\n",
    "train_labels = np.array([list(i) for i in train_labels])\n",
    "\n",
    "\n",
    "test_features = test_data[:, 0]\n",
    "test_features = np.array([list(i) for i in test_features]).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "test_labels = test_data[:, 1]\n",
    "test_labels = np.array([list(i) for i in test_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = TensorBoard()\n",
    "tb.set_model('VGG16(high_drop)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4514 samples, validate on 674 samples\n",
      "Epoch 141/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1445 - acc: 0.6176 - val_loss: 1.6772 - val_acc: 0.5593\n",
      "Epoch 142/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1675 - acc: 0.5981 - val_loss: 1.6802 - val_acc: 0.5608\n",
      "Epoch 143/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1424 - acc: 0.6072 - val_loss: 1.7322 - val_acc: 0.5445\n",
      "Epoch 144/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1952 - acc: 0.5961 - val_loss: 1.6584 - val_acc: 0.5282\n",
      "Epoch 145/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.1928 - acc: 0.5953 - val_loss: 1.6994 - val_acc: 0.5490\n",
      "Epoch 146/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1289 - acc: 0.6163 - val_loss: 1.6559 - val_acc: 0.5579\n",
      "Epoch 147/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1570 - acc: 0.6066 - val_loss: 1.7449 - val_acc: 0.5252\n",
      "Epoch 148/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1549 - acc: 0.6048 - val_loss: 1.7260 - val_acc: 0.5386\n",
      "Epoch 149/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1839 - acc: 0.6074 - val_loss: 1.7414 - val_acc: 0.5549\n",
      "Epoch 150/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1245 - acc: 0.6125 - val_loss: 1.7653 - val_acc: 0.5445\n",
      "Epoch 151/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1324 - acc: 0.6128 - val_loss: 1.8091 - val_acc: 0.5445\n",
      "Epoch 152/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1281 - acc: 0.6068 - val_loss: 1.6948 - val_acc: 0.5534\n",
      "Epoch 153/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0686 - acc: 0.6385 - val_loss: 1.7542 - val_acc: 0.5490\n",
      "Epoch 154/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1551 - acc: 0.6128 - val_loss: 1.7626 - val_acc: 0.5475\n",
      "Epoch 155/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.1250 - acc: 0.6154 - val_loss: 1.7711 - val_acc: 0.5504\n",
      "Epoch 156/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0765 - acc: 0.6325 - val_loss: 1.7874 - val_acc: 0.5445\n",
      "Epoch 157/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1227 - acc: 0.6114 - val_loss: 1.8441 - val_acc: 0.5445\n",
      "Epoch 158/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0900 - acc: 0.6236 - val_loss: 1.7817 - val_acc: 0.5504\n",
      "Epoch 159/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1407 - acc: 0.6156 - val_loss: 1.7734 - val_acc: 0.5430\n",
      "Epoch 160/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0976 - acc: 0.6225 - val_loss: 1.7348 - val_acc: 0.5519\n",
      "Epoch 161/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.1074 - acc: 0.6336 - val_loss: 1.8073 - val_acc: 0.5430\n",
      "Epoch 162/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0921 - acc: 0.6280 - val_loss: 1.7842 - val_acc: 0.5534\n",
      "Epoch 163/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0950 - acc: 0.6254 - val_loss: 1.8449 - val_acc: 0.5252\n",
      "Epoch 164/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.1308 - acc: 0.6167 - val_loss: 1.6921 - val_acc: 0.5608\n",
      "Epoch 165/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0771 - acc: 0.6303 - val_loss: 1.8319 - val_acc: 0.5341\n",
      "Epoch 166/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.1274 - acc: 0.6212 - val_loss: 1.7761 - val_acc: 0.5490\n",
      "Epoch 167/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.1033 - acc: 0.6331 - val_loss: 1.8710 - val_acc: 0.5386\n",
      "Epoch 168/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0725 - acc: 0.6276 - val_loss: 1.8608 - val_acc: 0.5341\n",
      "Epoch 169/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.1207 - acc: 0.6198 - val_loss: 1.8280 - val_acc: 0.5341\n",
      "Epoch 170/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0893 - acc: 0.6336 - val_loss: 1.8090 - val_acc: 0.5193\n",
      "Epoch 171/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.1118 - acc: 0.6274 - val_loss: 1.7367 - val_acc: 0.5445\n",
      "Epoch 172/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.1358 - acc: 0.6311 - val_loss: 1.7965 - val_acc: 0.5267\n",
      "Epoch 173/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.1334 - acc: 0.6150 - val_loss: 1.7093 - val_acc: 0.5490\n",
      "Epoch 174/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.1238 - acc: 0.6165 - val_loss: 1.8684 - val_acc: 0.5430\n",
      "Epoch 175/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.1342 - acc: 0.6212 - val_loss: 1.7836 - val_acc: 0.5534\n",
      "Epoch 176/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.1222 - acc: 0.6265 - val_loss: 1.7845 - val_acc: 0.5460\n",
      "Epoch 177/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0900 - acc: 0.6254 - val_loss: 1.8080 - val_acc: 0.5267\n",
      "Epoch 178/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0292 - acc: 0.6427 - val_loss: 1.8278 - val_acc: 0.5223\n",
      "Epoch 179/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0920 - acc: 0.6276 - val_loss: 1.8078 - val_acc: 0.5326\n",
      "Epoch 180/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0527 - acc: 0.6416 - val_loss: 1.7885 - val_acc: 0.5386\n",
      "Epoch 181/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0767 - acc: 0.6316 - val_loss: 1.8327 - val_acc: 0.5401\n",
      "Epoch 182/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0364 - acc: 0.6451 - val_loss: 1.7578 - val_acc: 0.5593\n",
      "Epoch 183/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0400 - acc: 0.6436 - val_loss: 1.7543 - val_acc: 0.5593\n",
      "Epoch 184/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0381 - acc: 0.6455 - val_loss: 1.7838 - val_acc: 0.5475\n",
      "Epoch 185/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0624 - acc: 0.6405 - val_loss: 1.7972 - val_acc: 0.5490\n",
      "Epoch 186/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0912 - acc: 0.6329 - val_loss: 1.7827 - val_acc: 0.5579\n",
      "Epoch 187/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0840 - acc: 0.6356 - val_loss: 1.6777 - val_acc: 0.5653\n",
      "Epoch 188/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0599 - acc: 0.6462 - val_loss: 1.7950 - val_acc: 0.5519\n",
      "Epoch 189/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0422 - acc: 0.6365 - val_loss: 1.7241 - val_acc: 0.5593\n",
      "Epoch 190/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0978 - acc: 0.6256 - val_loss: 1.7548 - val_acc: 0.5623\n",
      "Epoch 191/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0668 - acc: 0.6422 - val_loss: 1.7170 - val_acc: 0.5504\n",
      "Epoch 192/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1070 - acc: 0.6181 - val_loss: 1.7892 - val_acc: 0.5549\n",
      "Epoch 193/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1441 - acc: 0.6094 - val_loss: 1.7749 - val_acc: 0.5386\n",
      "Epoch 194/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.1003 - acc: 0.6300 - val_loss: 1.9229 - val_acc: 0.5445\n",
      "Epoch 195/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0172 - acc: 0.6471 - val_loss: 1.8884 - val_acc: 0.5386\n",
      "Epoch 196/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0370 - acc: 0.6467 - val_loss: 1.8255 - val_acc: 0.5579\n",
      "Epoch 197/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0049 - acc: 0.6540 - val_loss: 1.8766 - val_acc: 0.5534\n",
      "Epoch 198/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0768 - acc: 0.6345 - val_loss: 1.7323 - val_acc: 0.5490\n",
      "Epoch 199/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0352 - acc: 0.6484 - val_loss: 1.9009 - val_acc: 0.5564\n",
      "Epoch 200/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0222 - acc: 0.6486 - val_loss: 1.7649 - val_acc: 0.5549\n",
      "Epoch 201/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0738 - acc: 0.6429 - val_loss: 1.7380 - val_acc: 0.5697\n",
      "Epoch 202/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.1135 - acc: 0.6265 - val_loss: 1.8715 - val_acc: 0.5401\n",
      "Epoch 203/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0747 - acc: 0.6362 - val_loss: 1.8234 - val_acc: 0.5608\n",
      "Epoch 204/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0309 - acc: 0.6526 - val_loss: 1.8180 - val_acc: 0.5504\n",
      "Epoch 205/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0276 - acc: 0.6544 - val_loss: 1.9701 - val_acc: 0.5415\n",
      "Epoch 206/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0485 - acc: 0.6498 - val_loss: 1.8681 - val_acc: 0.5564\n",
      "Epoch 207/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0084 - acc: 0.6593 - val_loss: 1.8641 - val_acc: 0.5608\n",
      "Epoch 208/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0200 - acc: 0.6557 - val_loss: 1.8445 - val_acc: 0.5475\n",
      "Epoch 209/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0469 - acc: 0.6480 - val_loss: 1.8914 - val_acc: 0.5475\n",
      "Epoch 210/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0355 - acc: 0.6473 - val_loss: 1.8937 - val_acc: 0.5593\n",
      "Epoch 211/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0179 - acc: 0.6562 - val_loss: 1.9465 - val_acc: 0.5386\n",
      "Epoch 212/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0547 - acc: 0.6453 - val_loss: 1.9037 - val_acc: 0.5430\n",
      "Epoch 213/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0766 - acc: 0.6422 - val_loss: 1.8641 - val_acc: 0.5490\n",
      "Epoch 214/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0011 - acc: 0.6644 - val_loss: 1.8885 - val_acc: 0.5564\n",
      "Epoch 215/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9563 - acc: 0.6690 - val_loss: 2.0048 - val_acc: 0.5638\n",
      "Epoch 216/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9654 - acc: 0.6768 - val_loss: 1.8943 - val_acc: 0.5653\n",
      "Epoch 217/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9453 - acc: 0.6808 - val_loss: 2.0833 - val_acc: 0.5371\n",
      "Epoch 218/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9823 - acc: 0.6657 - val_loss: 1.9387 - val_acc: 0.5460\n",
      "Epoch 219/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9923 - acc: 0.6684 - val_loss: 1.8604 - val_acc: 0.5401\n",
      "Epoch 220/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 0.9837 - acc: 0.6675 - val_loss: 1.9367 - val_acc: 0.5490\n",
      "Epoch 221/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0665 - acc: 0.6407 - val_loss: 1.9766 - val_acc: 0.5386\n",
      "Epoch 222/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0404 - acc: 0.6542 - val_loss: 1.9101 - val_acc: 0.5445\n",
      "Epoch 223/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0943 - acc: 0.6351 - val_loss: 1.9229 - val_acc: 0.5282\n",
      "Epoch 224/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0789 - acc: 0.6316 - val_loss: 1.8394 - val_acc: 0.5490\n",
      "Epoch 225/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0228 - acc: 0.6613 - val_loss: 1.8906 - val_acc: 0.5430\n",
      "Epoch 226/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0385 - acc: 0.6411 - val_loss: 1.8923 - val_acc: 0.5534\n",
      "Epoch 227/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9466 - acc: 0.6828 - val_loss: 2.0535 - val_acc: 0.5326\n",
      "Epoch 228/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 0.9841 - acc: 0.6624 - val_loss: 2.0106 - val_acc: 0.5371\n",
      "Epoch 229/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 0.9694 - acc: 0.6701 - val_loss: 2.0277 - val_acc: 0.5401\n",
      "Epoch 230/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0141 - acc: 0.6630 - val_loss: 1.9630 - val_acc: 0.5490\n",
      "Epoch 231/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 0.9973 - acc: 0.6679 - val_loss: 1.9223 - val_acc: 0.5356\n",
      "Epoch 232/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0261 - acc: 0.6560 - val_loss: 1.9445 - val_acc: 0.5460\n",
      "Epoch 233/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 1.0020 - acc: 0.6624 - val_loss: 2.0601 - val_acc: 0.5445\n",
      "Epoch 234/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0231 - acc: 0.6557 - val_loss: 1.9130 - val_acc: 0.5519\n",
      "Epoch 235/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 0.9861 - acc: 0.6670 - val_loss: 1.9131 - val_acc: 0.5549\n",
      "Epoch 236/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 0.9769 - acc: 0.6679 - val_loss: 1.9762 - val_acc: 0.5415\n",
      "Epoch 237/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9976 - acc: 0.6606 - val_loss: 1.8243 - val_acc: 0.5534\n",
      "Epoch 238/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0025 - acc: 0.6653 - val_loss: 1.8962 - val_acc: 0.5430\n",
      "Epoch 239/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9886 - acc: 0.6622 - val_loss: 1.9871 - val_acc: 0.5504\n",
      "Epoch 240/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 0.9694 - acc: 0.6686 - val_loss: 2.0012 - val_acc: 0.5475\n",
      "Epoch 241/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9694 - acc: 0.6794 - val_loss: 2.0437 - val_acc: 0.5519\n",
      "Epoch 242/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9675 - acc: 0.6695 - val_loss: 1.9965 - val_acc: 0.5490\n",
      "Epoch 243/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9894 - acc: 0.6615 - val_loss: 2.0274 - val_acc: 0.5460\n",
      "Epoch 244/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9872 - acc: 0.6730 - val_loss: 1.9605 - val_acc: 0.5460\n",
      "Epoch 245/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9834 - acc: 0.6675 - val_loss: 2.0596 - val_acc: 0.5326\n",
      "Epoch 246/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9411 - acc: 0.6832 - val_loss: 2.0310 - val_acc: 0.5445\n",
      "Epoch 247/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9896 - acc: 0.6750 - val_loss: 1.9519 - val_acc: 0.5608\n",
      "Epoch 248/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9636 - acc: 0.6803 - val_loss: 1.9398 - val_acc: 0.5623\n",
      "Epoch 249/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9113 - acc: 0.6876 - val_loss: 1.9481 - val_acc: 0.5579\n",
      "Epoch 250/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0188 - acc: 0.6553 - val_loss: 1.9070 - val_acc: 0.5564\n",
      "Epoch 251/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0336 - acc: 0.6593 - val_loss: 1.9097 - val_acc: 0.5593\n",
      "Epoch 252/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9843 - acc: 0.6699 - val_loss: 1.9319 - val_acc: 0.5593\n",
      "Epoch 253/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9951 - acc: 0.6710 - val_loss: 1.9354 - val_acc: 0.5401\n",
      "Epoch 254/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9417 - acc: 0.6748 - val_loss: 1.9742 - val_acc: 0.5519\n",
      "Epoch 255/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9687 - acc: 0.6661 - val_loss: 1.9254 - val_acc: 0.5608\n",
      "Epoch 256/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0007 - acc: 0.6630 - val_loss: 1.9477 - val_acc: 0.5460\n",
      "Epoch 257/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0048 - acc: 0.6675 - val_loss: 2.0233 - val_acc: 0.5415\n",
      "Epoch 258/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9958 - acc: 0.6648 - val_loss: 1.8699 - val_acc: 0.5549\n",
      "Epoch 259/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9895 - acc: 0.6675 - val_loss: 1.9283 - val_acc: 0.5534\n",
      "Epoch 260/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0238 - acc: 0.6622 - val_loss: 1.9626 - val_acc: 0.5401\n",
      "Epoch 261/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 1.0007 - acc: 0.6648 - val_loss: 2.0519 - val_acc: 0.5326\n",
      "Epoch 262/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9588 - acc: 0.6741 - val_loss: 2.0729 - val_acc: 0.5608\n",
      "Epoch 263/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9816 - acc: 0.6704 - val_loss: 2.0525 - val_acc: 0.5490\n",
      "Epoch 264/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9562 - acc: 0.6755 - val_loss: 2.0040 - val_acc: 0.5371\n",
      "Epoch 265/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9244 - acc: 0.6887 - val_loss: 2.0072 - val_acc: 0.5519\n",
      "Epoch 266/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9212 - acc: 0.6861 - val_loss: 2.0884 - val_acc: 0.5430\n",
      "Epoch 267/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9087 - acc: 0.6914 - val_loss: 2.0286 - val_acc: 0.5415\n",
      "Epoch 268/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9457 - acc: 0.6739 - val_loss: 2.0448 - val_acc: 0.5549\n",
      "Epoch 269/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9264 - acc: 0.6890 - val_loss: 2.1507 - val_acc: 0.5415\n",
      "Epoch 270/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9372 - acc: 0.6797 - val_loss: 2.0253 - val_acc: 0.5549\n",
      "Epoch 271/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9606 - acc: 0.6755 - val_loss: 1.9233 - val_acc: 0.5757\n",
      "Epoch 272/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9407 - acc: 0.6797 - val_loss: 2.0306 - val_acc: 0.5490\n",
      "Epoch 273/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9199 - acc: 0.6887 - val_loss: 2.0687 - val_acc: 0.5549\n",
      "Epoch 274/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9668 - acc: 0.6768 - val_loss: 2.0827 - val_acc: 0.5549\n",
      "Epoch 275/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9649 - acc: 0.6794 - val_loss: 2.0189 - val_acc: 0.5519\n",
      "Epoch 276/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9615 - acc: 0.6761 - val_loss: 2.0481 - val_acc: 0.5386\n",
      "Epoch 277/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 0.9569 - acc: 0.6834 - val_loss: 1.9174 - val_acc: 0.5519\n",
      "Epoch 278/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 0.9921 - acc: 0.6761 - val_loss: 2.0418 - val_acc: 0.5534\n",
      "Epoch 279/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9451 - acc: 0.6814 - val_loss: 1.9316 - val_acc: 0.5727\n",
      "Epoch 280/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9734 - acc: 0.6699 - val_loss: 1.9892 - val_acc: 0.5549\n",
      "Epoch 281/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9615 - acc: 0.6790 - val_loss: 2.0546 - val_acc: 0.5386\n",
      "Epoch 282/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9149 - acc: 0.6956 - val_loss: 2.0381 - val_acc: 0.5371\n",
      "Epoch 283/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9468 - acc: 0.6843 - val_loss: 2.0410 - val_acc: 0.5460\n",
      "Epoch 284/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9250 - acc: 0.6967 - val_loss: 2.0886 - val_acc: 0.5371\n",
      "Epoch 285/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9510 - acc: 0.6783 - val_loss: 2.0073 - val_acc: 0.5460\n",
      "Epoch 286/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9490 - acc: 0.6779 - val_loss: 2.0951 - val_acc: 0.5430\n",
      "Epoch 287/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9395 - acc: 0.6887 - val_loss: 2.0980 - val_acc: 0.5312\n",
      "Epoch 288/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9315 - acc: 0.6848 - val_loss: 2.0242 - val_acc: 0.5415\n",
      "Epoch 289/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9807 - acc: 0.6730 - val_loss: 1.9963 - val_acc: 0.5504\n",
      "Epoch 290/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9643 - acc: 0.6737 - val_loss: 2.0059 - val_acc: 0.5371\n",
      "Epoch 291/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9469 - acc: 0.6879 - val_loss: 2.1285 - val_acc: 0.5504\n",
      "Epoch 292/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9103 - acc: 0.6923 - val_loss: 1.9711 - val_acc: 0.5593\n",
      "Epoch 293/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.8901 - acc: 0.6981 - val_loss: 2.0094 - val_acc: 0.5653\n",
      "Epoch 294/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9764 - acc: 0.6790 - val_loss: 2.1249 - val_acc: 0.5549\n",
      "Epoch 295/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9675 - acc: 0.6752 - val_loss: 1.9969 - val_acc: 0.5608\n",
      "Epoch 296/300\n",
      "4514/4514 [==============================] - 28s 6ms/step - loss: 0.9705 - acc: 0.6750 - val_loss: 1.9632 - val_acc: 0.5593\n",
      "Epoch 297/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 0.9630 - acc: 0.6794 - val_loss: 1.9714 - val_acc: 0.5593\n",
      "Epoch 298/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 0.9974 - acc: 0.6712 - val_loss: 2.0718 - val_acc: 0.5579\n",
      "Epoch 299/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 0.9259 - acc: 0.6839 - val_loss: 2.0379 - val_acc: 0.5638\n",
      "Epoch 300/300\n",
      "4514/4514 [==============================] - 27s 6ms/step - loss: 0.9290 - acc: 0.6786 - val_loss: 1.9964 - val_acc: 0.5593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21ab93f8898>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_features,\n",
    "          y=train_labels,\n",
    "          batch_size=64,\n",
    "          epochs=300,\n",
    "          validation_data=(test_features, test_labels),\n",
    "          verbose=1,\n",
    "          callbacks=[tb],\n",
    "          initial_epoch=140\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('.\\\\models\\\\VGG16(high_drop)\\\\VGG16(high_drop)-300_epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_square(image_current_path, shape):\n",
    "    \"\"\"Resize the image to a square shape keeping it's original proportion\n",
    "    and filling the rest of image with black pads to keep it square.\n",
    "\n",
    "    :param image_current_path: the local path where the image is.\n",
    "    :type image_current_path: OS string\n",
    "    :param shape: number of pixels per axis of the converted image\n",
    "    :type shape: int\n",
    "    :param save_path: path where the converted image must be saved\n",
    "    :type save_path: OS string\n",
    "    \"\"\"\n",
    "\n",
    "    original_image = cv2.imread(image_current_path, 1)\n",
    "    original_size = original_image.shape[:2]  # (height, width)\n",
    "\n",
    "    ratio = float(shape)/max(original_size)\n",
    "\n",
    "    format_size = tuple(reversed([int(i*ratio)\n",
    "                                  for i in original_size]))  # (width, height)\n",
    "\n",
    "    resized_image = cv2.resize(original_image, format_size)\n",
    "\n",
    "    d_w = shape - format_size[0]\n",
    "    d_h = shape - format_size[1]\n",
    "\n",
    "    top, bottom = d_h//2, d_h-(d_h//2)\n",
    "    left, right = d_w//2, d_w-(d_w//2)\n",
    "\n",
    "    color = [0, 0, 0]\n",
    "\n",
    "    squared_image = cv2.copyMakeBorder(\n",
    "        resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    return squared_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Shorthair - 0.00%\n",
      "Angora - 62.28%\n",
      "Ashera - 0.00%\n",
      "British Shorthair - 0.00%\n",
      "Exotic - 0.01%\n",
      "Himalayan - 4.32%\n",
      "Maine Coon - 0.03%\n",
      "Persian - 2.12%\n",
      "Ragdoll - 31.17%\n",
      "Siamese - 0.06%\n",
      "Sphynx - 0.00%\n"
     ]
    }
   ],
   "source": [
    "img = resize_square(IMAGE_TEST, IMAGE_SIZE)\n",
    "img = np.array(img)/255\n",
    "\n",
    "out = model.predict([img.reshape(-1, 150, 150, 3)])[0]\n",
    "\n",
    "for n in range(11):\n",
    "    print('{} - {:2.2f}%'.format(ONE_HOT[n], out[n]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
